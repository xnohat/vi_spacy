{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3tKYDikXYBo",
    "outputId": "07eb7aa6-7fef-4960-e173-1830577dc108"
   },
   "outputs": [],
   "source": [
    "pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ckkk1p3DQufT"
   },
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYW0dWuRQufX"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_RsnajtQufY"
   },
   "outputs": [],
   "source": [
    "nlp1 = spacy.load('C:\\\\Users\\\\xnoha\\\\miniconda3\\\\envs\\\\spacyner\\\\lib\\\\site-packages\\\\en_core_web_sm\\\\en_core_web_sm-2.1.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-wikg3XQufZ"
   },
   "source": [
    "## Working of NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7G7FLmvsQufZ"
   },
   "outputs": [],
   "source": [
    "docx1 = nlp1(u\"Who is Nishanth?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_oyr5nNSQufa",
    "outputId": "8c1d1c29-e2ad-4e6b-ccd9-0b2b5ed2a3f7"
   },
   "outputs": [],
   "source": [
    "for token in docx1.ents:\n",
    "    print(token.text,token.start_char, token.end_char,token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeQLi8NVQufb"
   },
   "outputs": [],
   "source": [
    "docx2 = nlp1(u\"Who is Kamal Khumar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1TP5-SNQufb",
    "outputId": "7c59d527-cc58-4a56-af7f-e6a83ada7c11"
   },
   "outputs": [],
   "source": [
    "for token in docx2.ents:\n",
    "    print(token.text,token.start_char, token.end_char,token.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSCuoJM5Qufc"
   },
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3R0TAoVQufd"
   },
   "outputs": [],
   "source": [
    "with open ('./phoner_train_word_spacy_ner', 'rb') as fp:\n",
    "    TRAIN_DATA = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ifz2GGeQufd"
   },
   "source": [
    "## Define our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MkkjgCGQufd"
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "output_dir=Path(\"./ner\")\n",
    "n_iter=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0ruhcJYQufe"
   },
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1jsCzTiQufe",
    "outputId": "2a6d1542-7ff7-452d-fbd5-fa832c0d5bf4"
   },
   "outputs": [],
   "source": [
    "if model is not None:\n",
    "    nlp = spacy.load(model)  \n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp = spacy.blank('vi')  \n",
    "    print(\"Created blank 'vi' model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mHdA4qrQuff"
   },
   "source": [
    "## Set up the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Te7ekB3ZQuff"
   },
   "outputs": [],
   "source": [
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q463hGCjQuff"
   },
   "source": [
    "## Train the Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSBAQRAgQufg",
    "outputId": "0d858964-1ac3-4ff0-9df4-653f3ddb1418"
   },
   "outputs": [],
   "source": [
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in tqdm(TRAIN_DATA):\n",
    "            nlp.update(\n",
    "                [text],  \n",
    "                [annotations],  \n",
    "                drop=0.5,  \n",
    "                sgd=optimizer,\n",
    "                losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zHzS0O5Qufg"
   },
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pA8ezzVKQufg"
   },
   "outputs": [],
   "source": [
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp(text)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfo5wScdQufh"
   },
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlqkkRPaQufh"
   },
   "outputs": [],
   "source": [
    "if output_dir is not None:\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DABVC0ExQufh"
   },
   "source": [
    "## Test the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Izea7h9FQufi"
   },
   "outputs": [],
   "source": [
    "print(\"Loading from\", output_dir)\n",
    "nlp2 = spacy.load(output_dir)\n",
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp2(text)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUSjz-FLQufi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NER solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
