{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3tKYDikXYBo",
    "outputId": "07eb7aa6-7fef-4960-e173-1830577dc108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvi in c:\\users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages (0.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages (from pyvi) (0.24.2)\n",
      "Requirement already satisfied: sklearn-crfsuite in c:\\users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages (from pyvi) (0.3.6)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages (from scikit-learn->pyvi) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages (from scikit-learn->pyvi) (1.20.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages (from scikit-learn->pyvi) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages (from scikit-learn->pyvi) (1.0.1)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
      "Requirement already satisfied: tabulate in c:\\users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
      "Requirement already satisfied: six in c:\\users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages (from sklearn-crfsuite->pyvi) (4.59.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plac in c:\\users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages (1.3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ckkk1p3DQufT"
   },
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "[+] Linking successful\n",
      "C:\\Users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages\\en_core_web_sm -->\n",
      "C:\\Users\\xnoha\\miniconda3\\envs\\spacyner\\lib\\site-packages\\spacy\\data\\en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You do not have sufficient privilege to perform this operation.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TYW0dWuRQufX"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "d_RsnajtQufY"
   },
   "outputs": [],
   "source": [
    "nlp1 = spacy.load('C:\\\\Users\\\\xnoha\\\\miniconda3\\\\envs\\\\spacyner\\\\lib\\\\site-packages\\\\en_core_web_sm\\\\en_core_web_sm-2.1.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-wikg3XQufZ"
   },
   "source": [
    "## Working of NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7G7FLmvsQufZ"
   },
   "outputs": [],
   "source": [
    "docx1 = nlp1(u\"Who is Nishanth?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_oyr5nNSQufa",
    "outputId": "8c1d1c29-e2ad-4e6b-ccd9-0b2b5ed2a3f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nishanth 7 15 PERSON\n"
     ]
    }
   ],
   "source": [
    "for token in docx1.ents:\n",
    "    print(token.text,token.start_char, token.end_char,token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LeQLi8NVQufb"
   },
   "outputs": [],
   "source": [
    "docx2 = nlp1(u\"Who is Kamal Khumar?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1TP5-SNQufb",
    "outputId": "7c59d527-cc58-4a56-af7f-e6a83ada7c11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kamal Khumar 7 19 PERSON\n"
     ]
    }
   ],
   "source": [
    "for token in docx2.ents:\n",
    "    print(token.text,token.start_char, token.end_char,token.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSCuoJM5Qufc"
   },
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "s3R0TAoVQufd"
   },
   "outputs": [],
   "source": [
    "with open ('./phoner_train_word_spacy_ner', 'rb') as fp:\n",
    "    TRAIN_DATA = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ifz2GGeQufd"
   },
   "source": [
    "## Define our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2MkkjgCGQufd"
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "output_dir=Path(\"./ner\")\n",
    "n_iter=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0ruhcJYQufe"
   },
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1jsCzTiQufe",
    "outputId": "2a6d1542-7ff7-452d-fbd5-fa832c0d5bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'vi' model\n"
     ]
    }
   ],
   "source": [
    "if model is not None:\n",
    "    nlp = spacy.load(model)  \n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp = spacy.blank('vi')  \n",
    "    print(\"Created blank 'vi' model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mHdA4qrQuff"
   },
   "source": [
    "## Set up the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Te7ekB3ZQuff"
   },
   "outputs": [],
   "source": [
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q463hGCjQuff"
   },
   "source": [
    "## Train the Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSBAQRAgQufg",
    "outputId": "0d858964-1ac3-4ff0-9df4-653f3ddb1418"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████████▍                             | 3073/4944 [04:45<02:53, 10.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a972afd6153c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 losses=losses)\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\spacyner\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m                 \u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrehearse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in tqdm(TRAIN_DATA):\n",
    "            nlp.update(\n",
    "                [text],  \n",
    "                [annotations],  \n",
    "                drop=0.5,  \n",
    "                sgd=optimizer,\n",
    "                losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zHzS0O5Qufg"
   },
   "source": [
    "## Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pA8ezzVKQufg"
   },
   "outputs": [],
   "source": [
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp(text)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfo5wScdQufh"
   },
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlqkkRPaQufh"
   },
   "outputs": [],
   "source": [
    "if output_dir is not None:\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DABVC0ExQufh"
   },
   "source": [
    "## Test the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Izea7h9FQufi"
   },
   "outputs": [],
   "source": [
    "print(\"Loading from\", output_dir)\n",
    "nlp2 = spacy.load(output_dir)\n",
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp2(text)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUSjz-FLQufi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NER solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
